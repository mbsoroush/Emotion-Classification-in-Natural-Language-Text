import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import numpy as np

# Page config
st.set_page_config(page_title="ğŸ“˜ Persian Emotion Classifier")

# App title
st.title("ğŸ“˜ Persian Emotion Classifier")

# Try loading the model and tokenizer
try:
    st.write("ğŸ”„ Loading model and tokenizer...")
    model = AutoModelForSequenceClassification.from_pretrained("parsbert-emotion")
    tokenizer = AutoTokenizer.from_pretrained("parsbert-emotion")
    labels = ['HAPPY', 'FEAR', 'SAD', 'HATE', 'ANGRY', 'SURPRISED', 'OTHER']
    st.success("âœ… Model loaded successfully from local folder.")
except Exception as e:
    st.error(f"âŒ Failed to load model: {e}")
    st.stop()

# Text input
text = st.text_area("ğŸ“ Enter Persian text to analyze emotion:")

# Button click
if st.button("ğŸ” Analyze Emotion"):
    if not text.strip():
        st.warning("âš ï¸ Please enter some text first.")
    else:
        try:
            # Tokenize input
            inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)

            # Predict
            with torch.no_grad():
                outputs = model(**inputs)
                probs = torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy()[0]

            # Show results
            st.write("### ğŸ“Š Prediction Results:")
            for i, prob in enumerate(probs):
                st.write(f"{labels[i]}: {prob:.2f}")

            # Show bar chart
            st.bar_chart(probs)

        except Exception as e:
            st.error(f"âŒ Error during prediction: {e}")
